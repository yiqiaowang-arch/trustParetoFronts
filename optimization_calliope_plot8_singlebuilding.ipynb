{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56782513d0b5ae86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T00:24:16.763400200Z",
     "start_time": "2023-12-23T00:24:11.717083500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wangy\\Documents\\GitHub\\calliope_optimization\\building.py:214: FutureWarning:\n",
      "\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "\n",
      "c:\\Users\\wangy\\Documents\\GitHub\\calliope_optimization\\building.py:293: FutureWarning:\n",
      "\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import calliope\n",
    "import pandas as pd\n",
    "from building import Building\n",
    "import geopandas as gpd\n",
    "import gc\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# import glob\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colorbar import ColorbarBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65a83d6a86d0d8b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T00:24:16.787289500Z",
     "start_time": "2023-12-23T00:24:16.756127900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calliope.set_log_verbosity(verbosity='error', include_solver_output=False, capture_warnings=False)\n",
    "# disable the warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "687a1a56bb3732e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T00:24:16.908879700Z",
     "start_time": "2023-12-23T00:24:16.868244400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_df_from_dbf(dbf_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Description: \n",
    "    The .dbf file is fully translated into this dataframe. \n",
    "    All datatypes are indicated automatically by pandas, thus needs manual modification later if needed.\n",
    "    Since the dbf contains all building's parameter generated by CEA, 'Name' column is set as index.\n",
    "    \n",
    "    Inputs:\n",
    "    dbf_path:   str, path of .dbf file\n",
    "\n",
    "    Return:\n",
    "    df:         pd.DataFrame, a dataframe indexed by building names. \n",
    "    \"\"\"\n",
    "\n",
    "    df: pd.DataFrame = gpd.read_file(dbf_path, ignore_geometry=True) # if ignore_geometry == True, then return a pd.DataFrame\n",
    "    df.set_index(\"Name\", inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e168228bad74e25c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T00:24:17.995358300Z",
     "start_time": "2023-12-23T00:24:16.883426400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scenario_folder = r'C:\\Users\\wangy\\OneDrive\\ETHY2FW\\IDP_Personal\\CEA\\2050 w3'\n",
    "zone_gdf = gpd.read_file(scenario_folder+r'\\inputs\\building-geometry\\zone.shp')\n",
    "zone_gdf.index = zone_gdf['Name']\n",
    "# create a new df using only the columns we need\n",
    "zone_df = pd.DataFrame()\n",
    "zone_df['Name'] = zone_gdf['Name']\n",
    "zone_df.set_index('Name', inplace=True)\n",
    "# # delete the Name column in zone_df\n",
    "# # typology_df = get_df_from_dbf(scenario_folder+r'\\inputs\\building-properties\\typology.dbf')\n",
    "# # zone_df = pd.concat([zone_df, typology_df['YEAR'], ], axis=1)\n",
    "# # zone_gdf['area'] = zone_gdf['geometry'].area\n",
    "# # zone_df = pd.concat([zone_df, zone_gdf['area'], zone_gdf['floors_ag']], axis=1)\n",
    "# # read typology file \n",
    "# # read the csv file containing if the building is inside district area\n",
    "# district_df = pd.read_csv(scenario_folder+r'\\inputs\\is_disheat.csv', index_col=0)\n",
    "# # merge the two df\n",
    "# zone_df = zone_df.merge(district_df, left_index=True, right_index=True)\n",
    "# # read the csv file containing if building is rebuilt\n",
    "# rebuild_df = pd.read_csv(scenario_folder+r'\\inputs\\Rebuild.csv', index_col=0)\n",
    "# # merge the two df, but since the zone_df has more columns, if rebuild_df doesn't contain some building, set the value to 0\n",
    "# zone_df = zone_df.merge(rebuild_df, left_index=True, right_index=True, how='left').fillna(0)\n",
    "# # read the csv file containing if the building is renovated\n",
    "# renovate_df = pd.read_csv(scenario_folder+r'\\inputs\\Renovation.csv', index_col=0)\n",
    "# # merge the two df, but since the zone_df has more columns, if renovate_df doesn't contain some building, set the value to 0\n",
    "# zone_df = zone_df.merge(renovate_df, left_index=True, right_index=True, how='left').fillna(0)\n",
    "# # read dbf file containing current building systems\n",
    "# current_heating_system_df = get_df_from_dbf(r\"C:\\Users\\wangy\\OneDrive\\ETHY2FW\\IDP_Personal\\CEA\\2023 Baseline\\inputs\\building-properties\\supply_systems.dbf\")[['type_hs']]\n",
    "# # leave only the type_hs column\n",
    "# # current_system_df = current_system_df[['type_hs']]\n",
    "# # merge the two df, but since the zone_df has more columns\n",
    "# zone_df = zone_df.merge(current_heating_system_df, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "126cf0cd7c3aa500",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T00:24:18.137713300Z",
     "start_time": "2023-12-23T00:24:18.112735800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # add indicating columns to guide adjusting AttrDict based on building's status\n",
    "# zone_df['is_disheat'] = zone_df['DisHeat'].astype(bool)\n",
    "# zone_df['is_rebuilt'] = zone_df['Rebuild'].astype(bool)\n",
    "# zone_df['is_renovated'] = zone_df['Renovation'].astype(bool)\n",
    "# zone_df['is_new'] = ~zone_df['is_rebuilt'] & ~zone_df['is_renovated']\n",
    "# zone_df['already_GSHP'] = zone_df['type_hs'] == 'SUPPLY_HEATING_AS6'\n",
    "# zone_df['already_ASHP'] = zone_df['type_hs'] == 'SUPPLY_HEATING_AS7'\n",
    "# zone_df['no_heat'] = zone_df['type_hs'] == 'SUPPLY_HEATING_AS0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aae7fbd03c0c015f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T00:24:18.471710700Z",
     "start_time": "2023-12-23T00:24:18.119801500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # get all dbfs from the following subfolder\n",
    "# dbf_folder = scenario_folder + r\"\\inputs\\building-properties\"\n",
    "# dbf_files = os.listdir(dbf_folder)\n",
    "# for file in dbf_files:\n",
    "#     if file.endswith(\".dbf\"):\n",
    "#         dbf_path = dbf_folder + \"\\\\\" + file\n",
    "#         df = get_df_from_dbf(dbf_path)\n",
    "#         # set the prefix of the column name to the name of the dbf file\n",
    "#         df.columns = [file[:-4] + \"_\" + col for col in df.columns]\n",
    "#         zone_df = pd.concat([zone_df, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "914e1a44daaced30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T00:24:19.222569900Z",
     "start_time": "2023-12-23T00:24:18.447382300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B162953 is already done\n",
      "B162948 is already done\n",
      "B162947 is already done\n",
      "B302011886 doesn't need heating\n",
      "B162917 is already done\n",
      "B2365661 is already done\n",
      "B162952 is already done\n",
      "B302012803 doesn't need heating\n",
      "B162935 is already done\n",
      "B162946 is already done\n",
      "B302024523 is already done\n",
      "B302024094 doesn't need heating\n",
      "B302024524 is already done\n",
      "B302013071 doesn't need heating\n",
      "B302024327 doesn't need heating\n",
      "B162920 is already done\n",
      "B302011676 doesn't need heating\n",
      "B302060757 doesn't need heating\n",
      "B162916 is already done\n",
      "B302022562 is already done\n",
      "B162581 is already done\n",
      "B302022561 is already done\n",
      "B162585 is already done\n",
      "B162579 is already done\n",
      "B162578 is already done\n",
      "B302024344 doesn't need heating\n",
      "B302011740 doesn't need heating\n",
      "B162396 is already done\n",
      "B162831 is already done\n",
      "B162482 is already done\n",
      "B162404 is already done\n",
      "B162446 is already done\n",
      "B302024101 doesn't need heating\n",
      "B162493 is already done\n",
      "B162930 is already done\n",
      "B162327 is already done\n",
      "B162510 is already done\n",
      "B2365747 is already done\n",
      "B302034411 is already done\n",
      "B302032606 is already done\n",
      "B302011894 doesn't need heating\n",
      "B302011958 doesn't need heating\n",
      "B302030812 is already done\n",
      "B162590 is already done\n",
      "B2365703 is already done\n",
      "B302030808 is already done\n",
      "B162495 is already done\n",
      "B162416 is already done\n",
      "B162605 is already done\n",
      "B162834 is already done\n",
      "B162420 is already done\n",
      "B302034645 is already done\n",
      "B302065793 is already done\n",
      "B302024497 doesn't need heating\n",
      "B162830 is already done\n",
      "B302012074 doesn't need heating\n",
      "B302064529 is already done\n",
      "B162588 is already done\n",
      "B162500 is already done\n",
      "B302023896 doesn't need heating\n",
      "B302063706 is already done\n",
      "B162496 is already done\n",
      "B302019762 doesn't need heating\n",
      "B162467 is already done\n",
      "B302021380 is already done\n",
      "B302019978 is already done\n",
      "B302024165 doesn't need heating\n",
      "B302024143 doesn't need heating\n",
      "B302030809 is already done\n",
      "B162862 is already done\n",
      "B302012488 doesn't need heating\n",
      "B302065100 is already done\n",
      "B162307 is already done\n",
      "B302065112 is already done\n",
      "B162848 is already done\n",
      "B302061111 is already done\n",
      "B302062589 is already done\n",
      "B162595 is already done\n",
      "B162597 is already done\n",
      "B2365699 is already done\n",
      "B162853 is already done\n",
      "B302020344 is already done\n",
      "B162858 is already done\n",
      "B302030821 is already done\n",
      "B302012852 is already done\n",
      "B302030810 is already done\n",
      "B302065787 is already done\n",
      "B162623 is already done\n",
      "B162859 is already done\n",
      "B302030823 is already done\n",
      "B162477 is already done\n",
      "B302011910 doesn't need heating\n",
      "B302065979 is already done\n",
      "B162398 is already done\n",
      "B302023917 doesn't need heating\n",
      "B302065980 is already done\n",
      "B302030817 is already done\n",
      "B302065792 is already done\n",
      "B302066357 is already done\n",
      "B302021222 doesn't need heating\n",
      "B162840 is already done\n",
      "B162620 is already done\n",
      "B162587 is already done\n",
      "B302066525 is already done\n",
      "B302064231 is already done\n",
      "B162442 is already done\n",
      "B162846 is already done\n",
      "B162950 is already done\n",
      "B162488 is already done\n",
      "the area of building B162402 is 72.12493955579414 m2\n",
      "{'co2': 1, 'monetary': 0}\n"
     ]
    },
    {
     "ename": "ApplicationError",
     "evalue": "No executable found for solver 'cplex'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mApplicationError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     15\u001b[0m building \u001b[38;5;241m=\u001b[39m Building(name\u001b[38;5;241m=\u001b[39mbuilding_name, scenario_path\u001b[38;5;241m=\u001b[39mscenario_folder, calliope_yaml_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/technology/techs_plot8_24h.yml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mbuilding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pareto_front\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mstore_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstore_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mbuilding_status\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten_spikes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten_percentile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.98\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mto_lp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_yaml\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m building\u001b[38;5;241m.\u001b[39mdf_pareto\u001b[38;5;241m.\u001b[39mto_csv(store_folder\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mbuilding_name\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_pareto.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\wangy\\Documents\\GitHub\\calliope_optimization\\building.py:334\u001b[0m, in \u001b[0;36mBuilding.get_pareto_front\u001b[1;34m(self, epsilon, store_folder, building_status, flatten_spikes, flatten_percentile, to_lp, to_yaml)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# first get the emission-optimal solution\u001b[39;00m\n\u001b[0;32m    330\u001b[0m model_emission \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_building_model(store_folder\u001b[38;5;241m=\u001b[39mstore_folder, \n\u001b[0;32m    331\u001b[0m                                          building_status\u001b[38;5;241m=\u001b[39mbuilding_status, flatten_spikes\u001b[38;5;241m=\u001b[39mflatten_spikes, \n\u001b[0;32m    332\u001b[0m                                          flatten_percentile\u001b[38;5;241m=\u001b[39mflatten_percentile, to_lp\u001b[38;5;241m=\u001b[39mto_lp, to_yaml\u001b[38;5;241m=\u001b[39mto_yaml, \n\u001b[0;32m    333\u001b[0m                                          obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memission\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 334\u001b[0m \u001b[43mmodel_emission\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m model_emission\u001b[38;5;241m.\u001b[39mto_netcdf(path\u001b[38;5;241m=\u001b[39mstore_folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_emission.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memission is done\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\wangy\\Documents\\GitHub\\calliope_optimization\\calliope\\lib\\site-packages\\calliope\\core\\model.py:266\u001b[0m, in \u001b[0;36mModel.run\u001b[1;34m(self, force_rerun, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moperate\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_data\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_operate_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    260\u001b[0m ):\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mModelError(\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to run this model in operational mode, probably because \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthere exist non-uniform timesteps (e.g. from time masking)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    264\u001b[0m     )\n\u001b[1;32m--> 266\u001b[0m results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend_model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend_model_opt, interface \u001b[38;5;241m=\u001b[39m \u001b[43mrun_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;66;03m# Add additional post-processed result variables to results\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mattrs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtermination_condition\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeasible\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\wangy\\Documents\\GitHub\\calliope_optimization\\calliope\\lib\\site-packages\\calliope\\backend\\run.py:46\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(model_data, timings, build_only)\u001b[0m\n\u001b[0;32m     43\u001b[0m run_config \u001b[38;5;241m=\u001b[39m AttrDict\u001b[38;5;241m.\u001b[39mfrom_yaml_string(model_data\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_config\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplan\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 46\u001b[0m     results, backend, opt \u001b[38;5;241m=\u001b[39m \u001b[43mrun_plan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBACKEND\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrun_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuild_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m run_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moperate\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     54\u001b[0m     results, backend, opt \u001b[38;5;241m=\u001b[39m run_operate(\n\u001b[0;32m     55\u001b[0m         model_data,\n\u001b[0;32m     56\u001b[0m         timings,\n\u001b[0;32m     57\u001b[0m         backend\u001b[38;5;241m=\u001b[39mBACKEND[run_config\u001b[38;5;241m.\u001b[39mbackend],\n\u001b[0;32m     58\u001b[0m         build_only\u001b[38;5;241m=\u001b[39mbuild_only,\n\u001b[0;32m     59\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\wangy\\Documents\\GitHub\\calliope_optimization\\calliope\\lib\\site-packages\\calliope\\backend\\run.py:125\u001b[0m, in \u001b[0;36mrun_plan\u001b[1;34m(model_data, timings, backend, build_only, backend_rerun, allow_warmstart, persistent, opt)\u001b[0m\n\u001b[0;32m    117\u001b[0m     solver \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_persistent\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    118\u001b[0m log_time(\n\u001b[0;32m    119\u001b[0m     logger,\n\u001b[0;32m    120\u001b[0m     timings,\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_solver_start\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    122\u001b[0m     comment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBackend: sending model to solver\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    123\u001b[0m )\n\u001b[1;32m--> 125\u001b[0m backend_results, opt \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolver_io\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolver_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_logs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_logs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarmstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m log_time(\n\u001b[0;32m    136\u001b[0m     logger,\n\u001b[0;32m    137\u001b[0m     timings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m     comment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBackend: solver finished running\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    141\u001b[0m )\n\u001b[0;32m    143\u001b[0m termination \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mload_results(backend_model, backend_results, opt)\n",
      "File \u001b[1;32mc:\\Users\\wangy\\Documents\\GitHub\\calliope_optimization\\calliope\\lib\\site-packages\\calliope\\backend\\pyomo\\model.py:230\u001b[0m, in \u001b[0;36msolve_model\u001b[1;34m(backend_model, solver, solver_io, solver_options, save_logs, opt, **solve_kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m             results \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39msolve(tee\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msolve_kwargs)\n\u001b[0;32m    229\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m             results \u001b[38;5;241m=\u001b[39m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtee\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msolve_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results, opt\n",
      "File \u001b[1;32mc:\\Users\\wangy\\Documents\\GitHub\\calliope_optimization\\calliope\\lib\\site-packages\\pyomo\\opt\\base\\solvers.py:513\u001b[0m, in \u001b[0;36mOptSolver.solve\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msolve\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m    511\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Solve the problem \"\"\"\u001b[39;00m\n\u001b[1;32m--> 513\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mavailable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexception_flag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;66;03m# If the inputs are models, then validate that they have been\u001b[39;00m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;66;03m# constructed! Collect suffix names to try and import from solution.\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyomo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblock\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _BlockData\n",
      "File \u001b[1;32mc:\\Users\\wangy\\Documents\\GitHub\\calliope_optimization\\calliope\\lib\\site-packages\\pyomo\\opt\\solver\\ilmcmd.py:37\u001b[0m, in \u001b[0;36mILMLicensedSystemCallSolver.available\u001b[1;34m(self, exception_flag)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_available:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mpyomo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshellcmd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSystemCallSolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mavailable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_flag\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     39\u001b[0m executable \u001b[38;5;241m=\u001b[39m pyomo\u001b[38;5;241m.\u001b[39mcommon\u001b[38;5;241m.\u001b[39mExecutable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124milmlist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\wangy\\Documents\\GitHub\\calliope_optimization\\calliope\\lib\\site-packages\\pyomo\\opt\\solver\\shellcmd.py:129\u001b[0m, in \u001b[0;36mSystemCallSolver.available\u001b[1;34m(self, exception_flag)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exception_flag:\n\u001b[0;32m    128\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo executable found for solver \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 129\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ApplicationError(msg \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mApplicationError\u001b[0m: No executable found for solver 'cplex'"
     ]
    }
   ],
   "source": [
    "# iterate through the zone_df to create the building objects and store them in a list\n",
    "store_folder = './pareto_no_wood'\n",
    "# check if building's name is already stored in subfolder result_per_building; if not, add it to the list\n",
    "for index, row in zone_df.iterrows():\n",
    "    building_name = str(index)\n",
    "    if building_name+'_pareto.csv' in os.listdir(store_folder):\n",
    "        print(building_name+' is already done')\n",
    "        continue\n",
    "    elif row[\"no_heat\"] == 1:\n",
    "        print(building_name+' doesn\\'t need heating')\n",
    "        continue\n",
    "    else: # building is not yet optimized, continue\n",
    "        pass\n",
    "\n",
    "    building = Building(name=building_name, scenario_path=scenario_folder, calliope_yaml_path='./data/technology/techs_plot8_24h.yml')\n",
    "    building.get_pareto_front(epsilon=3, \n",
    "                              store_folder=store_folder,\n",
    "                              building_status=row, flatten_spikes=True, flatten_percentile=0.98, \n",
    "                              to_lp=False, to_yaml=False)\n",
    "    building.df_pareto.to_csv(store_folder+'/'+building_name+'_pareto.csv')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eef93bad0ea2f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T04:52:36.628852Z",
     "start_time": "2023-12-21T03:31:01.031146700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# iterate through the zone_df get pareto front for each building and store output in a dictionary\n",
    "for building in building_list:\n",
    "    # if building doesn't need heating, skip it\n",
    "    if zone_df[building.name, \"no_heat\"] == 1:\n",
    "        print(building.name+' doesn\\'t need heating')\n",
    "        continue\n",
    "    \n",
    "    # if building is not in district heating area, skip it\n",
    "    building.get_pareto_front()\n",
    "    # save the df_pareto as csv\n",
    "    building.df_pareto.to_csv(store_folder+'/'+idx+'_pareto.csv')\n",
    "    del df_pareto\n",
    "    print(idx+' is done')\n",
    "    # clean up the rest of the memory\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b03fa7fe11d3260",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot setting\n",
    "# set style of plots\n",
    "plt.rcParams['font.family'] = 'Roboto'\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.rcParams['legend.loc'] = 'lower center'\n",
    "plt.rcParams['legend.frameon'] = False\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['axes.titley'] = 1.03\n",
    "plt.rcParams['figure.subplot.left'] = 0.08\n",
    "plt.rcParams['figure.subplot.right'] = 0.95\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "plt.rcParams['xtick.major.width'] = 2  # setting the x-axis tick width globally\n",
    "plt.rcParams['ytick.major.width'] = 2 # setting the y-axis tick width globally\n",
    "# set fig size\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e8b9c8f23f834",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T00:24:22.308151400Z",
     "start_time": "2023-12-23T00:24:19.213165200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate the coefficient of variation of each technology choice for each building and store them in a dataframe; in the end plot a bar chart with error bars for each technology in this dataframe.\n",
    "# the dataframe should have columns as technology names, and rows as building names\n",
    "# first define the dataframe column from one of the files in the folder;\n",
    "# then iterate through the rest of the files and add the data to the dataframe\n",
    "ls_csv = []\n",
    "for csv in os.listdir(store_folder):\n",
    "    if not csv.endswith('.csv'):\n",
    "        continue\n",
    "    ls_csv.append(csv)\n",
    "\n",
    "for idx, csv in enumerate(ls_csv):\n",
    "    # if the dataframe doesn't exist before, then define its columns with the first file\n",
    "    if idx == 0:\n",
    "        df_example = pd.read_csv('./pareto_no_wood/'+csv, index_col=0, nrows=1)\n",
    "        # add the first level index to be building name\n",
    "        df_example.index = pd.MultiIndex.from_tuples([(csv, i) for i in df_example.index], names=['building', 'epsilon'])\n",
    "        df_tech_cap = pd.DataFrame(columns=df_example.columns, index=df_example.index)\n",
    "        df_tech_cap = df_tech_cap.dropna(how='all')\n",
    "\n",
    "    building_sizing = pd.read_csv(store_folder+'/'+csv, index_col=0)\n",
    "    # # calculate the coefficient of variation for each technology\n",
    "    # df_tech_cap.loc[csv[:-10]] = building_sizing.std() / building_sizing.mean()\n",
    "    building_name = csv[:-11]\n",
    "    # if wood_boiler_DHW is 2000 at emission optimal (the first row), then it's oversized, change it to the DHW demand\n",
    "    if building_sizing.loc[0, 'wood_boiler_DHW'] == 2000:\n",
    "        building_sizing.loc[0, 'wood_boiler_DHW'] = building_sizing.loc[4, 'demand_hot_water']\n",
    "        building_sizing.loc[0, 'DHDC_small_heat'] = 0\n",
    "        building_sizing.loc[0, 'DHDC_medium_heat'] = 0\n",
    "        building_sizing.loc[0, 'DHDC_large_heat'] = 0\n",
    "    # if wood_boiler_heat is 2000 at emission optimal (the first row), then it's oversized, change it to the SH demand\n",
    "    if building_sizing.loc[0, 'wood_boiler_heat'] == 2000:\n",
    "        building_sizing.loc[0, 'wood_boiler_heat'] = building_sizing.loc[4, 'demand_space_heating']\n",
    "        \n",
    "    building_area = zone_df.loc[building_name, 'area'] * zone_df.loc[building_name, 'floors_ag']\n",
    "    # calculate the sizing per m2\n",
    "    building_sizing_per_m2 = building_sizing.fillna(0) / building_area\n",
    "    # add the first level index to be building name\n",
    "    building_sizing_per_m2.reset_index(drop=True, inplace=True)\n",
    "    building_sizing_per_m2.index = pd.MultiIndex.from_product([[building_name], building_sizing_per_m2.index], names=['building', 'epsilon'])\n",
    "    \n",
    "    # add the building_sizing_per_m2 to df_tech_cap to the bottom, but keep the multiindex\n",
    "    df_tech_cap = pd.concat([df_tech_cap, building_sizing_per_m2], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d37418cec97273",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T11:16:00.980844Z",
     "start_time": "2023-12-21T11:16:00.952255200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check if df_tech_cap has two levels of index\n",
    "df_tech_cap.index.nlevels\n",
    "# filter buildings that have GSHP. Refer to zone_df['already_GSHP'] for the boolean value, and refresh the df_tech_cap\n",
    "df_tech_cap = df_tech_cap[df_tech_cap.index.get_level_values('building').isin(zone_df[zone_df['is_disheat']].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648763b9769270aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T00:30:16.626619800Z",
     "start_time": "2023-12-23T00:30:16.135569600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "year_min = zone_df['YEAR'].min()\n",
    "year_max = zone_df['YEAR'].max()\n",
    "year_norm = mcolors.Normalize(vmin=year_min, vmax=year_max)\n",
    "colormap = plt.cm.get_cmap('viridis')\n",
    "for building_name in df_tech_cap.index.get_level_values('building').unique():\n",
    "    # get the df_pareto for this building\n",
    "    df_pareto = df_tech_cap.loc[building_name]\n",
    "    # find the building area\n",
    "    building_area = zone_df.loc[building_name, 'area'] * zone_df.loc[building_name, 'floors_ag']\n",
    "    # plot the pareto front, and matching the curve's color in colormap by building's year\n",
    "    building_year = zone_df.loc[building_name, 'YEAR']\n",
    "    building_color = colormap(year_norm(building_year))\n",
    "    # ignore the mission optimal point which is the first point\n",
    "    plt.plot(df_pareto['emission'].iloc[1:], \n",
    "             df_pareto['cost'].iloc[1:], \n",
    "             label=building_name, marker='.', color=building_color, linewidth=0.75)\n",
    "    \n",
    "plt.ylabel('cost [$CHF/m^2$]')\n",
    "plt.xlabel('emission [$kg/m^2$]')\n",
    "plt.title('Pareto Front, normalized by GFA', fontsize=24)\n",
    "plt.ylim(7, 65)\n",
    "plt.xlim(3, 26)\n",
    "# plt.xlim(1.5, 13)\n",
    "# plt.ylim(0, 50)\n",
    "# create a colorbar next to the plot, with the same height as the plot box\n",
    "cax = plt.axes([0.96, 0.11, 0.02, 0.77])\n",
    "cbar = ColorbarBase(cax, cmap=colormap, norm=year_norm)\n",
    "# label the building year on the left of the colorbar\n",
    "cbar.ax.set_ylabel('year of built')\n",
    "# plt.savefig(r'C:\\Users\\wangy\\polybox - Yiqiao Wang (yiqwang@student.ethz.ch)@polybox.ethz.ch\\Final Report\\Graphics\\ParetoFront_{}.pdf'.format(store_folder[9:]), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb065b113b05c53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T00:38:24.010196200Z",
     "start_time": "2023-12-23T00:38:21.531940400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,8))\n",
    "for building_name in df_tech_cap.index.get_level_values('building').unique():\n",
    "    # get the df_pareto for this building\n",
    "    df_pareto = df_tech_cap.loc[building_name]\n",
    "    # the first point is emission minimal, thus cost maximal; \n",
    "    # last one is cost minimal, thus emission maximal\n",
    "    # the slope defines how hard it is to reduce emission when sliding from cost minimal to emission minimal\n",
    "    y1 = df_pareto['cost'].iloc[0]\n",
    "    y2 = df_pareto['cost'].iloc[3]\n",
    "    x1 = df_pareto['emission'].iloc[0]\n",
    "    x2 = df_pareto['emission'].iloc[3]\n",
    "    emission_reduction_relative = (x2-x1)/x1*100 # percentage of emission reduction\n",
    "    cost_increase_absolute = y1-y2 # absolute cost increase\n",
    "    # label the points with building name next to the points\n",
    "    building_year = zone_df.loc[building_name, 'YEAR']\n",
    "    # building_area = zone_df.loc[building_name, 'area'] * zone_df.loc[building_name, 'floors_ag']\n",
    "    building_color = colormap(year_norm(building_year))\n",
    "    # find building typology \n",
    "    plt.scatter(cost_increase_absolute, emission_reduction_relative, label=building_name, marker='o', color=building_color)\n",
    "    # annotate the building name next to the point\n",
    "    if zone_df.loc[building_name, 'typology_1ST_USE'] not in ['SINGLE_RES', 'MULTI_RES']:\n",
    "        plt.annotate(zone_df.loc[building_name, 'typology_1ST_USE'], (cost_increase_absolute, emission_reduction_relative), \n",
    "                     fontsize=8, xytext=(0, 5), textcoords='offset points', ha='left')\n",
    "    \n",
    "plt.ylabel('Percentage of emission reduction [%]')\n",
    "plt.xlabel('Additional cost to reduce emission [$CHF/m^2$]')\n",
    "plt.xlim(0, 150)\n",
    "plt.ylim(0, 40)\n",
    "# plot a line from (0,0) to (100, 1) and extend to the right\n",
    "plt.plot([0, 75], [0, 40], color='k', linestyle='--', linewidth=0.5)\n",
    "plt.plot([0, 150], [0, 40], color='k', linestyle='--', linewidth=0.5)\n",
    "plt.plot([0, 250], [0, 40], color='k', linestyle='--', linewidth=0.5)\n",
    "plt.plot([0, 400], [0, 40], color='k', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# plot a horizontal line at 800\n",
    "# plt.axhline(y=900, color='k', linestyle='--', linewidth=0.5)\n",
    "# plt.axhline(y=530, color='k', linestyle='--', linewidth=0.5)\n",
    "plt.title('Fraction of total emission reduction', fontsize=24)\n",
    "\n",
    "# again, plot a colorbar next to the plot, with the same height as the plot box\n",
    "cax = plt.axes([0.96, 0.11, 0.02, 0.77])\n",
    "cbar = ColorbarBase(cax, cmap=colormap, norm=year_norm)\n",
    "# label the building year on the left of the colorbar\n",
    "cbar.ax.set_ylabel('year of built')\n",
    "\n",
    "plt.savefig(r'C:\\Users\\wangy\\polybox - Yiqiao Wang (yiqwang@student.ethz.ch)@polybox.ethz.ch\\Final Report\\Graphics\\relative_{}_thinner.pdf'.format(store_folder[9:]), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c6d2130c814afa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T00:38:58.068760600Z",
     "start_time": "2023-12-23T00:38:54.383676700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,8))\n",
    "for building_name in df_tech_cap.index.get_level_values('building').unique():\n",
    "    # get the df_pareto for this building\n",
    "    df_pareto = df_tech_cap.loc[building_name]\n",
    "    # the first point is emission minimal, thus cost maximal; \n",
    "    # last one is cost minimal, thus emission maximal\n",
    "    # the slope defines how hard it is to reduce emission when sliding from cost minimal to emission minimal\n",
    "    y1 = df_pareto['cost'].iloc[0]\n",
    "    y2 = df_pareto['cost'].iloc[3]\n",
    "    x1 = df_pareto['emission'].iloc[0]\n",
    "    x2 = df_pareto['emission'].iloc[3]\n",
    "    emission_reduction_absolute = x2-x1 # percentage of emission reduction\n",
    "    cost_increase_absolute = y1-y2 # absolute cost increase\n",
    "    # label the points with building name next to the points\n",
    "    building_year = zone_df.loc[building_name, 'YEAR']\n",
    "    # building_area = zone_df.loc[building_name, 'area'] * zone_df.loc[building_name, 'floors_ag']\n",
    "    building_color = colormap(year_norm(building_year))\n",
    "    # find building typology \n",
    "    plt.scatter(cost_increase_absolute, emission_reduction_absolute, label=building_name, marker='o', color=building_color)\n",
    "    # annotate the building name next to the point\n",
    "    if zone_df.loc[building_name, 'typology_1ST_USE'] not in ['SINGLE_RES', 'MULTI_RES']:\n",
    "        plt.annotate(zone_df.loc[building_name, 'typology_1ST_USE'], (cost_increase_absolute, emission_reduction_absolute), \n",
    "                     fontsize=8, xytext=(0, 5), textcoords='offset points', ha='left')\n",
    "    \n",
    "plt.ylabel('Absolute emission reduction [$kg/m^2$]')\n",
    "plt.xlabel('Additional cost to reduce emission [$CHF/m^2$]')\n",
    "plt.xlim(0, 150)\n",
    "plt.ylim(0, 2.25)\n",
    "# set y ticks to tick only every 0.5\n",
    "plt.yticks(np.arange(0, 2.25, 0.5))\n",
    "# plot a line from (0,0) to (100, 1) and extend to the right\n",
    "plt.plot([0, 75], [0, 2.25], color='k', linestyle='--', linewidth=0.5)\n",
    "plt.plot([0, 150], [0, 2.25], color='k', linestyle='--', linewidth=0.5)\n",
    "plt.plot([0, 250], [0, 2.25], color='k', linestyle='--', linewidth=0.5)\n",
    "plt.plot([0, 400], [0, 2.25], color='k', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# plot a horizontal line at 800\n",
    "# plt.axhline(y=900, color='k', linestyle='--', linewidth=0.5)\n",
    "# plt.axhline(y=530, color='k', linestyle='--', linewidth=0.5)\n",
    "plt.title('Total emission reduction', fontsize=24)\n",
    "\n",
    "# again, plot a colorbar next to the plot, with the same height as the plot box\n",
    "cax = plt.axes([0.96, 0.11, 0.02, 0.77])\n",
    "cbar = ColorbarBase(cax, cmap=colormap, norm=year_norm)\n",
    "# label the building year on the left of the colorbar\n",
    "cbar.ax.set_ylabel('year of built')\n",
    "\n",
    "plt.savefig(r'C:\\Users\\wangy\\polybox - Yiqiao Wang (yiqwang@student.ethz.ch)@polybox.ethz.ch\\Final Report\\Graphics\\absolute_{}_thinner.pdf'.format(store_folder[9:]), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed67ca16bb1790c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T13:33:44.570582600Z",
     "start_time": "2023-12-22T13:33:42.191095200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for building_name in df_tech_cap.index.get_level_values('building').unique():\n",
    "    # get the df_pareto for this building\n",
    "    df_pareto = df_tech_cap.loc[building_name]\n",
    "    # the first point is emission minimal, thus cost maximal; \n",
    "    # last one is cost minimal, thus emission maximal\n",
    "    # the slope defines how hard it is to reduce emission when sliding from cost minimal to emission minimal\n",
    "    y1 = df_pareto['cost'].iloc[1]\n",
    "    y2 = df_pareto['cost'].iloc[4]\n",
    "    x1 = df_pareto['emission'].iloc[1]\n",
    "    x2 = df_pareto['emission'].iloc[4]\n",
    "    slope = -(y2-y1)/(x2-x1)\n",
    "    average_emission = (df_pareto['emission'].iloc[-3] + df_pareto['emission'].iloc[1]) / 2\n",
    "    # label the points with building name next to the points\n",
    "    building_year = zone_df.loc[building_name, 'YEAR']\n",
    "    # building_area = zone_df.loc[building_name, 'area'] * zone_df.loc[building_name, 'floors_ag']\n",
    "    building_color = colormap(year_norm(building_year))\n",
    "    # find building typology \n",
    "    plt.scatter(average_emission, slope, label=building_name, marker='o', color=building_color)\n",
    "    # annotate the building name next to the point\n",
    "    if zone_df.loc[building_name, 'typology_1ST_USE'] not in ['SINGLE_RES', 'MULTI_RES']:\n",
    "        plt.annotate(zone_df.loc[building_name, 'typology_1ST_USE'], (average_emission, slope), \n",
    "                     fontsize=8, xytext=(0, 5), textcoords='offset points', ha='left')\n",
    "    # add name of the building next to the point\n",
    "    # plt.annotate(building_name, (average_emission, slope), fontsize=8, xytext=(0, 5), textcoords='offset points', ha='left')\n",
    "    \n",
    "plt.ylabel('Elasticity of cost to emission [-]')\n",
    "plt.xlabel('Average emission [$kg/m^2$]')\n",
    "# plt.xlim(3, 26)\n",
    "# plt.ylim(1.8, 4.9)\n",
    "# plot a horizontal line at 800\n",
    "# plt.axhline(y=900, color='k', linestyle='--', linewidth=0.5)\n",
    "# plt.axhline(y=530, color='k', linestyle='--', linewidth=0.5)\n",
    "plt.title('Difficulties for buildings to reduce emission', fontsize=24)\n",
    "\n",
    "# again, plot a colorbar next to the plot, with the same height as the plot box\n",
    "cax = plt.axes([0.96, 0.11, 0.02, 0.77])\n",
    "cbar = ColorbarBase(cax, cmap=colormap, norm=year_norm)\n",
    "# label the building year on the left of the colorbar\n",
    "cbar.ax.set_ylabel('year of built')\n",
    "\n",
    "# plt.savefig(r'C:\\Users\\wangy\\polybox - Yiqiao Wang (yiqwang@student.ethz.ch)@polybox.ethz.ch\\Final Report\\Graphics\\ParetoFront_elasticity_{}.pdf'.format(store_folder[9:]), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6db185c6e96305",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T00:25:26.927119Z",
     "start_time": "2023-12-23T00:25:25.084818200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate the demand technologies\n",
    "df_demand_tech = df_tech_cap[df_tech_cap.columns[-4:]]\n",
    "df_supply_tech = df_tech_cap[df_tech_cap.columns[:-4]]\n",
    "\n",
    "# Create a figure with two subplots side by side, with a shared y-axis and width ratio of 3:1\n",
    "fig, axs = plt.subplots(1, 2, sharey=True,figsize=(20, 6), gridspec_kw={'width_ratios': [4, 1]})\n",
    "\n",
    "# Boxplot without outliers and with a custom hatch pattern\n",
    "boxprops = dict(linestyle='-', linewidth=1, color='k')  # Custom box properties\n",
    "medianprops = dict(linestyle='-', linewidth=0.5, color='k')  # Custom median properties\n",
    "\n",
    "# Create a color map for the five epsilon cuts\n",
    "cmap = plt.cm.get_cmap('RdYlGn', 5)# 5 distinct colors for 5 epsilon cuts\n",
    "# reverse the color map so that the emission optimal is green\n",
    "cmap = cmap.reversed()\n",
    "\n",
    "# Create a boxplot for each technology\n",
    "for i, tech in enumerate(df_supply_tech.columns):\n",
    "    # Get the data for the current technology\n",
    "    tech_data = df_supply_tech[tech].values.reshape(-1, 5)  # Reshape the data to have 5 rows for each technology\n",
    "    bp = axs[0].boxplot(tech_data, positions=np.arange(i*5, i*5+5), patch_artist=True, showfliers=False, boxprops=boxprops, medianprops=medianprops)\n",
    "\n",
    "    # Fill each box with a color according to its epsilon cut\n",
    "    for j, box in enumerate(bp['boxes']):\n",
    "        box.set(facecolor=cmap(j))\n",
    "\n",
    "# Define your colors for the demand technologies\n",
    "demand_colors = ['tab:green', 'tab:orange', 'tab:blue', 'tab:red']\n",
    "\n",
    "# Create a boxplot for each demand technology, but only one box per technology\n",
    "for i, tech in enumerate(df_demand_tech.columns):\n",
    "    # calculate the mean of each technology in five epsilon cuts\n",
    "    tech_data = df_demand_tech[tech].values.reshape(-1, 5).mean(axis=1)\n",
    "    bp = axs[1].boxplot(tech_data, positions=[i], patch_artist=True, showfliers=False, boxprops=boxprops, medianprops=medianprops, widths=0.5)  # Set position to a single value and adjust the width\n",
    "    # Fill each box with a color according to its epsilon cut\n",
    "    for j, box in enumerate(bp['boxes']):\n",
    "        box.set(facecolor=demand_colors[i])\n",
    "\n",
    "# Set the x-axis labels to the technology names\n",
    "axs[0].set_xticks(np.arange(2.5, len(df_supply_tech.columns)*5, 5))  # Set x-ticks to the middle box of each technology group\n",
    "axs[0].set_xticklabels(df_supply_tech.columns, rotation=45)\n",
    "\n",
    "# Align the x-axis labels to the right\n",
    "for label in axs[0].get_xticklabels():\n",
    "    label.set_horizontalalignment('right')\n",
    "\n",
    "# Draw vertical lines to separate the technologies inbetween the boundary boxes, not on the box\n",
    "for i in range(5, len(df_supply_tech.columns)*5, 5):\n",
    "    axs[0].axvline(x=i-0.5, color='k', linestyle='--', linewidth=0.5)  # Subtract 0.5 from the x position\n",
    "\n",
    "# set the second subplot's x axis to be the same as the first one, but only one box per technology\n",
    "axs[1].set_xticks(range(len(df_demand_tech.columns)))  # Set x-ticks to the middle box of each technology group\n",
    "axs[1].set_xticklabels(df_demand_tech.columns, rotation=45)\n",
    "\n",
    "for label in axs[1].get_xticklabels():\n",
    "    label.set_horizontalalignment('right')\n",
    "# Set the title and axis labels\n",
    "axs[0].set_title('Variation of Building Technologies', fontsize=24)\n",
    "axs[1].set_title('Variation of Demand', fontsize=24)\n",
    "axs[0].set_ylabel('Specific Sizing of Technologies [$kW/m^2$]', fontsize=14)\n",
    "\n",
    "# Create a custom legend for the epsilon cuts\n",
    "ls_epsilon_cut = ['Emission Optimal', 'Epsilon 1', 'Epsilon 2', 'Epsilon 3', 'Cost Optimal']\n",
    "legend_patches = [mpatches.Patch(color=cmap(i), label=ls_epsilon_cut[i]) for i in range(5)]\n",
    "axs[0].legend(handles=legend_patches, loc='upper left')\n",
    "\n",
    "# print a horizontal line at 0 for both subplots\n",
    "axs[0].axhline(y=0, color='k', linestyle='--', linewidth=0.5)\n",
    "axs[1].axhline(y=0, color='k', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Set the y-axis limits\n",
    "axs[0].set_ylim(-0.005, 0.09)\n",
    "# make the two plots a bit closer\n",
    "plt.subplots_adjust(wspace=0.05)\n",
    "# Tight layout to adjust padding\n",
    "# plt.tight_layout()\n",
    "\n",
    "plt.savefig(r'C:\\Users\\wangy\\polybox - Yiqiao Wang (yiqwang@student.ethz.ch)@polybox.ethz.ch\\Final Report\\Graphics\\Variation_{}_shorter.pdf'.format(store_folder[9:]), dpi=300, bbox_inches='tight')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17c0ef07442c61e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## explore different clustering of building against pareto front\n",
    "1. The goal is to compare buildings with different DH capex. If five buildings are using the same DH outlet, then every building should only share 1/5 of the DH capex. \n",
    "2. There are some buildings that belongs to the same developer. These buildings can be clustered and share the DH capex. Below I will list the buildings that belongs to the same developer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611e4c157f16598d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## test for one building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e224581ae576f79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T17:29:11.681435800Z",
     "start_time": "2023-12-20T17:28:48.484617900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "building = Building('B302030807', scenario_folder)\n",
    "building.flatten_spikes_demand(percentile=0.98) # flatten the demand spikes\n",
    "dict_timeseries_df = {'demand_el': building.app,\n",
    "                      'demand_sh': building.sh,\n",
    "                      'demand_dhw': building.dhw,\n",
    "                      'demand_sc': building.sc,\n",
    "                      'supply_PV': building.pv_intensity,\n",
    "                      'supply_PVT_e': building.pvt_e_intensity,\n",
    "                      'supply_PVT_h': building.pvt_h_relative_intensity,\n",
    "                      'supply_SCFP': building.scfp_intensity\n",
    "                      }\n",
    "row = zone_df.loc[building.name]\n",
    "# modify the building_specific_config to match the building's status\n",
    "building_specific_config: calliope.AttrDict = calliope.AttrDict.from_yaml('./data/technology/techs_plot8.yml')\n",
    "building_specific_config.set_key(key='locations.Building.available_area', value=building.area)\n",
    "print('the area of building '+building.name+' is '+str(building.area)+' m2')\n",
    "building_sub_dict = building_specific_config['locations'].pop('Building')\n",
    "building_specific_config['locations'][building.name] = building_sub_dict\n",
    "\n",
    "# update geothermal storage max capacity\n",
    "building_specific_config.set_key(key=f'locations.{building.name}.techs.geothermal_boreholes.constraints.energy_cap_max',\n",
    "                                 value=(building.area+400)*0.1) # assume 100W/m2 max yield\n",
    "# if building is not in district heating area, delete the district heating technologies keys\n",
    "if not row['is_disheat']:\n",
    "    building_specific_config.del_key(f'locations.{building.name}.techs.DHDC_small_heat')\n",
    "    building_specific_config.del_key(f'locations.{building.name}.techs.DHDC_medium_heat')\n",
    "    building_specific_config.del_key(f'locations.{building.name}.techs.DHDC_large_heat')\n",
    "\n",
    "# if building is already equipped with GSHP, set the GSHP purchase cost to 0\n",
    "if row['already_GSHP']:\n",
    "    building_specific_config.set_key(f'locations.{building.name}.techs.GSHP_heat.costs.monetary.purchase', 0)\n",
    "    building_specific_config.set_key(f'locations.{building.name}.techs.GSHP_heat.costs.monetary.energy_cap', 0)\n",
    "\n",
    "# if building is already equipped with ASHP, set the ASHP purchase cost to 0\n",
    "if row['already_ASHP']:\n",
    "    building_specific_config.set_key(f'locations.{building.name}.techs.ASHP.costs.monetary.purchase', 0)\n",
    "    building_specific_config.set_key(f'locations.{building.name}.techs.ASHP.costs.monetary.energy_cap', 0)\n",
    "\n",
    "# if building is not rebuilt, set GSHP and ASHP costs higher\n",
    "if not row['is_rebuilt']:\n",
    "    if not row['already_GSHP']:\n",
    "        building_specific_config.set_key(f'locations.{building.name}.techs.GSHP_heat.costs.monetary.purchase', 39934)\n",
    "        building_specific_config.set_key(f'locations.{building.name}.techs.GSHP_heat.costs.monetary.energy_cap', 1316)\n",
    "    if not row['already_ASHP']:\n",
    "        building_specific_config.set_key(f'locations.{building.name}.techs.ASHP.costs.monetary.purchase', 18086)\n",
    "        building_specific_config.set_key(f'locations.{building.name}.techs.ASHP.costs.monetary.energy_cap', 1360)\n",
    "\n",
    "    # if building is not new, delete the GSHP technology keys\n",
    "if not row['is_new']:\n",
    "    building_specific_config.del_key(f'locations.{building.name}.techs.GSHP_heat')\n",
    "    building_specific_config.del_key(f'locations.{building.name}.techs.GSHP_cooling')\n",
    "    building_specific_config.del_key(f'locations.{building.name}.techs.geothermal_boreholes')\n",
    "\n",
    "# # test: delete ASHP\n",
    "# building_specific_config.del_key(f'locations.{building.name}.techs.ASHP')        \n",
    "\n",
    "model = calliope.Model(building_specific_config, timeseries_dataframes=dict_timeseries_df)\n",
    "# model.to_lp('./result_site_specific_2/'+building.name+'.lp')\n",
    "model.run()\n",
    "# model.save_commented_model_yaml('./result_site_specific_2/'+building.name+'.yaml')\n",
    "# # save to result_per_building, which is a subfolder of current working directory\n",
    "# model.to_netcdf(path='./result_site_specific_2/'+building.name+'.nc')\n",
    "# # calculate how many percent of the buildings are done, including the current one and its name\n",
    "# # calculate how many .nc files are in the subfolder, but some files are not .nc files, so len(os.listdir()) is not accurate\n",
    "# number_of_nc_files = len(glob.glob('./result_site_specific_2/*.nc'))\n",
    "# print('including '+building.name+', '+str(round(number_of_nc_files/len(zone_df.index)*100, 2))+'% of the buildings are done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a644efb916f7b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T17:29:17.375527200Z",
     "start_time": "2023-12-20T17:29:17.091304Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_tech_cost = model.get_formatted_array('cost').sel(locs='B302030807').to_pandas().transpose()\n",
    "model_energy_cap = model.get_formatted_array('energy_cap').to_pandas().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbea72864d148c50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T17:29:38.628517Z",
     "start_time": "2023-12-20T17:29:38.537407700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model = calliope.read_netcdf('./result_site_specific_2/B302030807.nc')\n",
    "model_geostore_prod = model.get_formatted_array('carrier_prod').sel(carriers='geothermal_storage', locs='B302030807').to_pandas().transpose()\n",
    "model_geostore_con = model.get_formatted_array('carrier_con').sel(carriers='geothermal_storage', locs='B302030807').to_pandas().transpose()\n",
    "model_geostore_all = model_geostore_prod.merge(model_geostore_con, left_index=True, right_index=True)\n",
    "\n",
    "model_sh_prod = model.get_formatted_array('carrier_prod').sel(carriers='heat', locs='B302030807').to_pandas().transpose()\n",
    "model_sh_con = model.get_formatted_array('carrier_con').sel(carriers='heat', locs='B302030807').to_pandas().transpose()\n",
    "model_sh_all = model_sh_prod.merge(model_sh_con, left_index=True, right_index=True)\n",
    "\n",
    "model_el_prod = model.get_formatted_array('carrier_prod').sel(carriers='electricity', locs='B302030807').to_pandas().transpose()\n",
    "model_el_con = model.get_formatted_array('carrier_con').sel(carriers='electricity', locs='B302030807').to_pandas().transpose()\n",
    "model_el_all = model_el_prod.merge(model_el_con, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8db34ba75d0fa46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T17:29:40.655375100Z",
     "start_time": "2023-12-20T17:29:39.962762800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the model_geostore_all, with x axis as timestep, and four ys: geothermal_boreholes_x, geothermal_boreholes_y, GSHP_heat_y, GSHP_cooling_x\n",
    "plt.plot(model_geostore_all.index, model_geostore_all['geothermal_boreholes_x'], color='red', alpha=0.5)\n",
    "plt.plot(model_geostore_all.index, model_geostore_all['geothermal_boreholes_y'], color='blue', alpha=0.5)\n",
    "plt.plot(model_geostore_all.index, model_geostore_all['GSHP_heat_y'], color='green', alpha=0.5)\n",
    "plt.plot(model_geostore_all.index, model_geostore_all['GSHP_cooling_x'], color='orange', alpha=0.5)\n",
    "plt.legend(['geothermal_boreholes_x', 'geothermal_boreholes_y', 'GSHP_heat_y', 'GSHP_cooling_x'], loc='upper right')\n",
    "plt.title('geothermal storage used by technologies')\n",
    "plt.ylabel('energy [kWh]')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(model_sh_all.index, model_sh_all['demand_space_heating'], color='red', alpha=0.5)\n",
    "plt.plot(model_sh_all.index, model_sh_all['GSHP_heat_x'], color='green', alpha=0.5)\n",
    "plt.plot(model_sh_all.index, model_sh_all['wood_boiler_heat_x'], color='blue', alpha=0.5)\n",
    "plt.legend(['demand_space_heating', 'GSHP_heat_x', 'wood_boiler_heat_x'], loc='upper right')\n",
    "plt.title('space heating demand and technologies')\n",
    "plt.ylabel('energy [kWh]')\n",
    "plt.show()\n",
    "\n",
    "# plot in model_el_all, with x axis as timestep, and ys: PV, battery_x, battery_y, grid, GSHP_heat_y, GSHP_cooling_y\n",
    "plt.plot(model_el_all.index, model_el_all['demand_electricity'], color='red', alpha=0.5)\n",
    "plt.plot(model_el_all.index, model_el_all['PV'], color='green', alpha=0.5)\n",
    "plt.plot(model_el_all.index, model_el_all['battery_x'], color='blue', alpha=0.5)\n",
    "plt.plot(model_el_all.index, model_el_all['battery_y'], color='orange', alpha=0.5)\n",
    "plt.plot(model_el_all.index, model_el_all['grid'], color='purple', alpha=0.5)\n",
    "plt.legend(['demand_electricity', 'PV', 'battery_x', 'battery_y', 'grid'], loc='upper right')\n",
    "plt.title('electricity demand and technologies')\n",
    "plt.ylabel('energy [kWh]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a426b2facbc830d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
